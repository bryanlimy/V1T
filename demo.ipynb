{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Demo code to load the best V1T model and inference on the Sensorium+ test set\n",
    "\n",
    "Please follow the instruction in [README.md](README.md) to set up the conda environment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import torch\n",
    "import typing as t\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from v1t import data\n",
    "from v1t.utils import utils\n",
    "from v1t.models import Model\n",
    "from v1t.metrics import Metrics\n",
    "from v1t.utils.scheduler import Scheduler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "dummy arg object to mimic argparse"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cpu\")\n",
    "        self.batch_size = 16\n",
    "        self.output_dir = \"runs/best_v1t_sensorium\"\n",
    "        self.dataset = \"data/sensorium\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "args = Args()\n",
    "utils.load_args(args)  # load arguments from checkpoint"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "load Sensorium+ test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "_, _, test_ds = data.get_training_ds(\n",
    "    args,\n",
    "    data_dir=args.dataset,\n",
    "    mouse_ids=args.mouse_ids,\n",
    "    batch_size=args.batch_size,\n",
    "    device=args.device,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "initialize model and restore checkpoint"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded checkpoint from epoch 120 (correlation: 0.4612).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model(args, ds=test_ds)\n",
    "model.to(args.device)\n",
    "\n",
    "scheduler = Scheduler(args, model=model, save_optimizer=False)\n",
    "_ = scheduler.restore(force=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def inference(\n",
    "    ds: DataLoader,\n",
    "    model: torch.nn.Module,\n",
    "    batch_size: int,\n",
    "    device: torch.device = \"cpu\",\n",
    ") -> t.Dict[str, torch.Tensor]:\n",
    "    \"\"\"Inference data in DataLoader ds\n",
    "    Returns:\n",
    "        results: t.Dict[int, t.Dict[str, torch.Tensor]]\n",
    "            - mouse_id\n",
    "                - predictions: torch.Tensor, predictions given images\n",
    "                - targets: torch.Tensor, the ground-truth responses\n",
    "                - trial_ids: torch.Tensor, trial ID of the responses\n",
    "                - image_ids: torch.Tensor, image ID of the responses\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        \"predictions\": [],\n",
    "        \"targets\": [],\n",
    "        \"trial_ids\": [],\n",
    "        \"image_ids\": [],\n",
    "    }\n",
    "    mouse_id = ds.dataset.mouse_id\n",
    "    model.to(device)\n",
    "    model.train(False)\n",
    "    for batch in tqdm(ds, desc=f\"Mouse {data.convert_id(mouse_id)}\"):\n",
    "        for micro_batch in data.micro_batching(batch, batch_size=batch_size):\n",
    "            predictions, _, _ = model(\n",
    "                inputs=micro_batch[\"image\"].to(device),\n",
    "                mouse_id=mouse_id,\n",
    "                behaviors=micro_batch[\"behavior\"].to(device),\n",
    "                pupil_centers=micro_batch[\"pupil_center\"].to(device),\n",
    "            )\n",
    "            results[\"predictions\"].append(predictions.cpu())\n",
    "            results[\"targets\"].append(micro_batch[\"response\"])\n",
    "            results[\"image_ids\"].append(micro_batch[\"image_id\"])\n",
    "            results[\"trial_ids\"].append(micro_batch[\"trial_id\"])\n",
    "    results = {\n",
    "        k: torch.cat(v, dim=0) if isinstance(v[0], torch.Tensor) else v\n",
    "        for k, v in results.items()\n",
    "    }\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mouse A: 100%|██████████| 63/63 [01:54<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single trial correlation: 0.401\n",
      "correlation to average: 0.597\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mouse B: 100%|██████████| 63/63 [01:53<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single trial correlation: 0.464\n",
      "correlation to average: 0.666\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mouse C: 100%|██████████| 62/62 [01:52<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single trial correlation: 0.430\n",
      "correlation to average: 0.638\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mouse D: 100%|██████████| 63/63 [01:52<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single trial correlation: 0.436\n",
      "correlation to average: 0.637\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mouse E:  71%|███████▏  | 45/63 [01:15<00:29,  1.61s/it]"
     ]
    }
   ],
   "source": [
    "for mouse_id in [\"2\", \"3\", \"4\", \"5\", \"6\"]:\n",
    "    outputs = inference(\n",
    "        ds=test_ds[mouse_id],\n",
    "        model=model,\n",
    "        batch_size=args.batch_size,\n",
    "        device=args.device,\n",
    "    )\n",
    "    metrics = Metrics(ds=test_ds[mouse_id], results=outputs)\n",
    "\n",
    "    single_trial_correlation = metrics.single_trial_correlation(per_neuron=False)\n",
    "    correlation_to_average = metrics.correlation_to_average(per_neuron=False)\n",
    "    print(\n",
    "        f\"single trial correlation: {single_trial_correlation:.03f}\\n\"\n",
    "        f\"correlation to average: {correlation_to_average:.03f}\\n\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract attention rollout maps for Mouse A\n",
    "\n",
    "See [misc/vit_visualization.py](misc/vit_visualization.py) for more."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from v1t.utils import tensorboard\n",
    "from v1t.utils.attention_rollout import attention_rollout, Recorder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_attention_map(\n",
    "    val_results: t.List[t.Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]],\n",
    "    test_results: t.List[t.Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]],\n",
    "    colormap: str = \"turbo\",\n",
    "    alpha: float = 0.5,\n",
    "):\n",
    "    assert len(val_results) == len(test_results) == 3\n",
    "    cmap = cm.get_cmap(colormap)\n",
    "    colors = cmap(np.arange(256))[:, :3]\n",
    "    label_fontsize, tick_fontsize = 10, 8\n",
    "    figure, axes = plt.subplots(\n",
    "        nrows=2,\n",
    "        ncols=3,\n",
    "        figsize=(8, 4),\n",
    "        gridspec_kw={\"wspace\": 0.05, \"hspace\": -0.25},\n",
    "        dpi=240,\n",
    "        facecolor=\"white\",\n",
    "    )\n",
    "    for i, (image, heatmap, behavior, pupil_center) in enumerate(val_results):\n",
    "        image = image[0]\n",
    "        heatmap = colors[np.uint8(255.0 * heatmap)] * 255.0\n",
    "        image = image[..., None]\n",
    "        heatmap = alpha * heatmap + (1 - alpha) * image\n",
    "        axes[0, i].imshow(heatmap.astype(np.uint8), cmap=colormap)\n",
    "        axes[0, i].set_xticks([])\n",
    "        axes[0, i].set_yticks([])\n",
    "        tensorboard.remove_spines(axis=axes[0, i])\n",
    "        description = (\n",
    "            f\"[{behavior[0]:.01f}, \"  # pupil dilation\n",
    "            f\"{behavior[1]:.01f}, \"  # dilation derivative\n",
    "            f\"({pupil_center[0]:.01f}, {pupil_center[1]:.01f}), \"  # pupil center\n",
    "            f\"{behavior[2]:.01f}]\"  # speed\n",
    "        )\n",
    "        axes[0, i].set_xlabel(description, labelpad=0, fontsize=tick_fontsize)\n",
    "    axes[0, 0].set_ylabel(\"Validation samples\", labelpad=0.05, fontsize=tick_fontsize)\n",
    "    for i, (image, heatmap, behavior, pupil_center) in enumerate(test_results):\n",
    "        image = image[0]\n",
    "        heatmap = colors[np.uint8(255.0 * heatmap)] * 255.0\n",
    "        image = image[..., None]\n",
    "        heatmap = alpha * heatmap + (1 - alpha) * image\n",
    "        axes[1, i].imshow(heatmap.astype(np.uint8), cmap=colormap)\n",
    "        axes[1, i].set_xticks([])\n",
    "        axes[1, i].set_yticks([])\n",
    "        tensorboard.remove_spines(axis=axes[1, i])\n",
    "        description = (\n",
    "            f\"[{behavior[0]:.01f}, \"  # pupil dilation\n",
    "            f\"{behavior[1]:.01f}, \"  # dilation derivative\n",
    "            f\"({pupil_center[0]:.01f}, {pupil_center[1]:.01f}), \"  # pupil center\n",
    "            f\"{behavior[2]:.01f}]\"  # speed\n",
    "        )\n",
    "        axes[1, i].set_xlabel(description, labelpad=0, fontsize=tick_fontsize)\n",
    "    axes[-1, 0].set_ylabel(\"Test samples\", labelpad=0.05, fontsize=tick_fontsize)\n",
    "\n",
    "    # plot colorbar\n",
    "    pos1 = axes[0, -1].get_position()\n",
    "    pos2 = axes[-1, -1].get_position()\n",
    "    width, height = 0.008, (pos1.y1 - pos1.y0) * 0.35\n",
    "    cbar_ax = figure.add_axes(\n",
    "        rect=[\n",
    "            pos1.x1 + 0.01,\n",
    "            ((pos1.y1 - pos2.y0) / 2 + pos2.y0) - (height / 2),\n",
    "            width,\n",
    "            height,\n",
    "        ]\n",
    "    )\n",
    "    figure.colorbar(cm.ScalarMappable(cmap=colormap), cax=cbar_ax, shrink=0.1)\n",
    "    tensorboard.set_yticks(\n",
    "        axis=cbar_ax,\n",
    "        ticks_loc=np.linspace(0, 1, 3),\n",
    "        tick_fontsize=tick_fontsize,\n",
    "    )\n",
    "    tensorboard.set_ticks_params(axis=cbar_ax)\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "load validation and test set with batch size of 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, val_ds, test_ds = data.get_training_ds(\n",
    "    args,\n",
    "    data_dir=args.dataset,\n",
    "    mouse_ids=args.mouse_ids,\n",
    "    batch_size=1,\n",
    "    device=args.device,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_plots = 3  # number of maps to extract from each set\n",
    "mouse_id = \"2\"  # mouse 2 -> mouse A\n",
    "recorder = Recorder(model.core)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_results = []\n",
    "for batch in val_ds[mouse_id]:\n",
    "    with torch.no_grad():\n",
    "        pupil_center = batch[\"pupil_center\"]\n",
    "        # pupil_center = torch.zeros_like(pupil_center)\n",
    "        behavior = batch[\"behavior\"]\n",
    "        # behavior = torch.zeros_like(behavior)\n",
    "        image, _ = model.image_cropper(\n",
    "            inputs=batch[\"image\"],\n",
    "            mouse_id=mouse_id,\n",
    "            behaviors=behavior,\n",
    "            pupil_centers=pupil_center,\n",
    "        )\n",
    "        _, attention = recorder(\n",
    "            images=image,\n",
    "            behaviors=behavior,\n",
    "            pupil_centers=pupil_center,\n",
    "            mouse_id=mouse_id,\n",
    "        )\n",
    "        image = val_ds[mouse_id].dataset.i_transform_image(image)\n",
    "        recorder.clear()\n",
    "    image, attention = image.numpy()[0], attention.numpy()[0]\n",
    "    heatmap = attention_rollout(image=image, attention=attention)\n",
    "    val_results.append((image, heatmap, behavior.numpy()[0], pupil_center.numpy()[0]))\n",
    "    if len(val_results) == num_plots:\n",
    "        break\n",
    "\n",
    "test_results = []\n",
    "for batch in test_ds[mouse_id]:\n",
    "    with torch.no_grad():\n",
    "        pupil_center = batch[\"pupil_center\"]\n",
    "        behavior = batch[\"behavior\"]\n",
    "        image, _ = model.image_cropper(\n",
    "            inputs=batch[\"image\"],\n",
    "            mouse_id=mouse_id,\n",
    "            behaviors=behavior,\n",
    "            pupil_centers=pupil_center,\n",
    "        )\n",
    "        _, attention = recorder(\n",
    "            images=image,\n",
    "            behaviors=behavior,\n",
    "            pupil_centers=pupil_center,\n",
    "            mouse_id=mouse_id,\n",
    "        )\n",
    "        image = val_ds[mouse_id].dataset.i_transform_image(image)\n",
    "        recorder.clear()\n",
    "    image, attention = image.numpy()[0], attention.numpy()[0]\n",
    "    heatmap = attention_rollout(image=image, attention=attention)\n",
    "    test_results.append((image, heatmap, behavior.numpy()[0], pupil_center.numpy()[0]))\n",
    "    if len(test_results) == num_plots:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_attention_map(val_results=val_results, test_results=test_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Please check [misc/](misc/) for code to generate plots and figures used in the paper."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
