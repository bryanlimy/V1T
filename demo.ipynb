{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Demo code to load the best V1T model and inference on the test set\n",
    "\n",
    "Please follow the instruction in [README.md](README.md) to setup the conda environment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import typing as t\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sensorium import data\n",
    "from sensorium.utils import utils\n",
    "from sensorium.models import Model\n",
    "from sensorium.metrics import Metrics\n",
    "from sensorium.utils.scheduler import Scheduler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "dummy arg object to mimic argparse"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cpu\")\n",
    "        self.batch_size = 16\n",
    "        self.output_dir = \"runs/best_v1t\"\n",
    "        self.dataset = \"data/sensorium\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "args = Args()\n",
    "utils.load_args(args)  # load arguments from checkpoint"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "load test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "test_ds, _ = data.get_submission_ds(\n",
    "    args,\n",
    "    data_dir=args.dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    device=args.device,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "initialize model and restore checkpoint"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded checkpoint from epoch 120 (correlation: 0.4612).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model(args, ds=test_ds)\n",
    "model.to(args.device)\n",
    "\n",
    "scheduler = Scheduler(args, model=model, save_optimizer=False)\n",
    "_ = scheduler.restore(force=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def inference(\n",
    "    ds: DataLoader,\n",
    "    model: torch.nn.Module,\n",
    "    batch_size: int,\n",
    "    device: torch.device = \"cpu\",\n",
    ") -> t.Dict[str, torch.Tensor]:\n",
    "    \"\"\"Inference data in DataLoader ds\n",
    "    Returns:\n",
    "        results: t.Dict[int, t.Dict[str, torch.Tensor]]\n",
    "            - mouse_id\n",
    "                - predictions: torch.Tensor, predictions given images\n",
    "                - targets: torch.Tensor, the ground-truth responses\n",
    "                - trial_ids: torch.Tensor, trial ID of the responses\n",
    "                - image_ids: torch.Tensor, image ID of the responses\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        \"predictions\": [],\n",
    "        \"targets\": [],\n",
    "        \"trial_ids\": [],\n",
    "        \"image_ids\": [],\n",
    "    }\n",
    "    mouse_id = ds.dataset.mouse_id\n",
    "    model.to(device)\n",
    "    model.train(False)\n",
    "    for batch in tqdm(ds, desc=f\"Mouse {data.convert_id(mouse_id)}\"):\n",
    "        for micro_batch in data.micro_batching(batch, batch_size=batch_size):\n",
    "            predictions, _, _ = model(\n",
    "                inputs=micro_batch[\"image\"].to(device),\n",
    "                mouse_id=mouse_id,\n",
    "                behaviors=micro_batch[\"behavior\"].to(device),\n",
    "                pupil_centers=micro_batch[\"pupil_center\"].to(device),\n",
    "            )\n",
    "            results[\"predictions\"].append(predictions.cpu())\n",
    "            results[\"targets\"].append(micro_batch[\"response\"])\n",
    "            results[\"image_ids\"].append(micro_batch[\"image_id\"])\n",
    "            results[\"trial_ids\"].append(micro_batch[\"trial_id\"])\n",
    "    results = {\n",
    "        k: torch.cat(v, dim=0) if isinstance(v[0], torch.Tensor) else v\n",
    "        for k, v in results.items()\n",
    "    }\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mouse A:   3%|â–Ž         | 2/63 [00:03<02:00,  1.98s/it]"
     ]
    }
   ],
   "source": [
    "for mouse_id in [\"2\", \"3\", \"4\", \"5\", \"6\"]:\n",
    "    outputs = inference(\n",
    "        ds=test_ds[mouse_id],\n",
    "        model=model,\n",
    "        batch_size=args.batch_size,\n",
    "        device=args.device,\n",
    "    )\n",
    "    metrics = Metrics(ds=test_ds[mouse_id], results=outputs)\n",
    "\n",
    "    single_trial_correlation = metrics.single_trial_correlation(per_neuron=False)\n",
    "    correlation_to_average = metrics.correlation_to_average(per_neuron=False)\n",
    "    print(\n",
    "        f\"single trial correlation: {single_trial_correlation:.03f}\\n\"\n",
    "        f\"correlation to average: {correlation_to_average:.03f}\\n\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
